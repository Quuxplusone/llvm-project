// -*- C++ -*-
//===----------------------------------------------------------------------===//
//
// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//===----------------------------------------------------------------------===//

#ifndef _LIBCPP_HIVE
#define _LIBCPP_HIVE

#include <__algorithm/fill_n.h>
#include <__algorithm/sort.h>
#include <__bit/bit_cast.h>
#include <__config>
#include <__functional/operations.h>
#include <__iterator/concepts.h>
#include <__iterator/distance.h>
#include <__iterator/iterator_traits.h>
#include <__iterator/move_iterator.h>
#include <__iterator/reverse_iterator.h>
#include <__memory/addressof.h>
#include <__memory/allocator.h>
#include <__memory/allocator_traits.h>
#include <__memory/pointer_traits.h>
#include <__memory/unique_ptr.h>
#include <__type_traits/conditional.h>
#include <__type_traits/enable_if.h>
#include <__type_traits/is_trivial.h>
#include <__type_traits/is_trivially_copyable.h>
#include <__type_traits/is_trivially_destructible.h>
#include <__type_traits/type_identity.h>
#include <__utility/exchange.h>
#include <__utility/forward.h>
#include <__utility/move.h>
#include <cstddef>
#include <limits>
#include <stdexcept>
#include <version>

// standard-mandated includes

// [hive.syn]
#include <compare>
#include <initializer_list>

#if !defined(_LIBCPP_HAS_NO_PRAGMA_SYSTEM_HEADER)
#  pragma GCC system_header
#endif

#if _LIBCPP_STD_VER >= 23

_LIBCPP_PUSH_MACROS
#include <__undef_macros>

_LIBCPP_BEGIN_NAMESPACE_STD

// Copyright (c) 2022, Matthew Bentley (mattreecebentley@gmail.com) www.plflib.org
// Modified by Arthur O'Dwyer, 2022. Original source:
// https://github.com/mattreecebentley/plf_hive/blob/7b7763f/plf_hive.h

// zLib license (https://www.zlib.net/zlib_license.html):
// This software is provided 'as-is', without any express or implied
// warranty. In no event will the authors be held liable for any damages
// arising from the use of this software.
//
// Permission is granted to anyone to use this software for any purpose,
// including commercial applications, and to alter it and redistribute it
// freely, subject to the following restrictions:
//
// 1. The origin of this software must not be misrepresented; you must not
//  claim that you wrote the original software. If you use this software
//  in a product, an acknowledgement in the product documentation would be
//  appreciated but is not required.
// 2. Altered source versions must be plainly marked as such, and must not be
//  misrepresented as being the original software.
// 3. This notice may not be removed or altered from any source distribution.

#ifndef PLF_HIVE_P2596
 #define PLF_HIVE_P2596 0
#endif

#ifndef PLF_HIVE_RANDOM_ACCESS_ITERATORS
 #define PLF_HIVE_RANDOM_ACCESS_ITERATORS 0
#endif

#if PLF_HIVE_RANDOM_ACCESS_ITERATORS
 #define PLF_HIVE_RELATIONAL_OPERATORS 1  // random access iterators require relational operators
#endif

#ifndef PLF_HIVE_RELATIONAL_OPERATORS
 #define PLF_HIVE_RELATIONAL_OPERATORS 1
#endif

#ifndef PLF_HIVE_DEBUGGING
 #define PLF_HIVE_DEBUGGING 0
#endif

template<class R>
struct hive_txn {
    R& rollback_;
    bool done_ = false;
    explicit hive_txn(R& rollback) : rollback_(rollback) {}
    ~hive_txn() { if (!done_) rollback_(); }
};

template<class F, class R>
static inline void hive_try_rollback(F&& task, R&& rollback) {
    hive_txn<R> txn(rollback);
    task();
    txn.done_ = true;
}

template<class F, class R>
static inline void hive_try_finally(F&& task, R&& finally) {
    hive_txn<R> txn(finally);
    task();
}

#if !PLF_HIVE_P2596
struct hive_limits {
    constexpr hive_limits(size_t mn, size_t mx) noexcept : min(mn), max(mx) {}
    size_t min, max;
};
#endif

template <class T, class allocator_type = std::allocator<T>>
class hive {
    template<bool _IsConst> class __hive_iterator;
    template<bool _IsConst> class __hive_reverse_iterator;
    friend class __hive_iterator<false>;
    friend class __hive_iterator<true>;

    using _SkipfieldType = unsigned short;
    using _AllocTraits = std::allocator_traits<allocator_type>;

public:
    using value_type = T;
    using size_type = typename _AllocTraits::size_type;
    using difference_type = typename _AllocTraits::difference_type;
    using pointer = typename _AllocTraits::pointer;
    using const_pointer = typename _AllocTraits::const_pointer;
    using reference = T&;
    using const_reference = const T&;
    using iterator = __hive_iterator<false>;
    using const_iterator = __hive_iterator<true>;
    using reverse_iterator = __hive_reverse_iterator<false>;
    using const_reverse_iterator = __hive_reverse_iterator<true>;

private:
    inline auto make_value_callback(size_type, const T& value) {
        struct CB {
            const T& value_;
            void construct_and_increment(allocator_type& ea, _AlignedEltPtr& p) {
                std::allocator_traits<allocator_type>::construct(ea, p[0].t(), value_);
                ++p;
            }
        };
        return CB{value};
    }

    template<class It, class Sent>
    inline auto make_itpair_callback(It& first, Sent&) {
        struct CB {
            It& first_;
            void construct_and_increment(allocator_type& ea, _AlignedEltPtr& p) {
                std::allocator_traits<allocator_type>::construct(ea, p[0].t(), *first_);
                ++p;
                ++first_;
            }
        };
        return CB{first};
    }

    template<class U> using AllocOf = typename std::allocator_traits<allocator_type>::template rebind_alloc<U>;
    template<class U> using PtrOf = typename std::allocator_traits<AllocOf<U>>::pointer;

    struct overaligned_elt {
        union {
            char dummy_;
            struct {
                _SkipfieldType nextlink_;
                _SkipfieldType prevlink_;
            };
            T t_;
        };
        PtrOf<T> t() { return bitcast_pointer<PtrOf<T>>(std::addressof(t_)); }
    };

    template <class D, class S>
    static constexpr D bitcast_pointer(S source_pointer) {
        return std::bit_cast<D>(std::to_address(source_pointer));
    }

    struct group;
    using _AlignedEltPtr = PtrOf<overaligned_elt>;
    using _GroupPtr = PtrOf<group>;
    using _SkipfieldPtr = PtrOf<_SkipfieldType>;

    struct group {
        _AlignedEltPtr last_endpoint;
            // The address which is one-past the highest cell number that's been used so far in this group - does not change via erasure
            // but may change via insertion/emplacement/assignment (if no previously-erased locations are available to insert to).
            // This variable is necessary because an iterator cannot access the hive's __end_. It is probably the most-used variable
            // in general hive usage (being heavily used in operator ++, --), so is first in struct. If all cells in the group have
            // been inserted into at some point, it will be == reinterpret_cast<_AlignedEltPtr>(skipfield).
        _GroupPtr next_group = nullptr;
        _GroupPtr prev_group = nullptr;
        _SkipfieldType free_list_head = std::numeric_limits<_SkipfieldType>::max();
            // The index of the last erased element in the group. The last erased element will, in turn, contain
            // the number of the index of the next erased element, and so on. If this is == maximum _SkipfieldType value
            // then free_list is empty ie. no erasures have occurred in the group.
        _SkipfieldType capacity;
        _SkipfieldType size = 0;
            // The total number of active elements in group - changes with insert and erase commands - used to check for empty group in erase function,
            // as an indication to remove the group. Also used in combination with capacity to check if group is full.
        _GroupPtr next_erasure_ = nullptr;
            // The next group in the singly-linked list of groups with erasures ie. with active erased-element free lists. nullptr if no next group.
#if PLF_HIVE_RELATIONAL_OPERATORS
        size_type groupno_ = 0;
            // Used for comparison (> < >= <= <=>) iterator operators (used by distance function and user).
#endif

#if PLF_HIVE_RELATIONAL_OPERATORS
        inline size_t group_number() const { return groupno_; }
        inline void set_group_number(size_type x) { groupno_ = x; }
#else
        inline size_t group_number() const { return 42; }
        inline void set_group_number(size_type) { }
#endif

#if PLF_HIVE_DEBUGGING
        void debug_dump() {
            printf(
                "  group #%zu [%zu/%zu used] (last_endpoint=%p, elts=%p, skipfield=%p, freelist=%zu, erasenext=%p)",
                group_number(), size_t(size), size_t(capacity),
                (void*)last_endpoint, (void*)addr_of_element(0), (void*)addr_of_skipfield(0), size_t(free_list_head), (void*)next_erasure_
            );
            if (next_group) {
                printf(" next: #%zu", next_group->group_number());
            } else {
                printf(" next: null");
            }
            if (prev_group) {
                printf(" prev: #%zu\n", prev_group->group_number());
            } else {
                printf(" prev: null\n");
            }
            printf("  skipfield[] =");
            for (int i = 0; i < capacity; ++i) {
                if (skipfield(i) == 0) {
                    printf(" _");
                } else {
                    printf(" %d", int(skipfield(i)));
                }
            }
            if (skipfield(capacity) == 0) {
                printf(" [_]\n");
            } else {
                printf(" [%d]\n", int(skipfield(capacity)));
            }
        }
#endif // PLF_HIVE_DEBUGGING

        explicit group(_SkipfieldType cap) :
            last_endpoint(addr_of_element(0)), capacity(cap)
        {
            std::fill_n(addr_of_skipfield(0), cap + 1, _SkipfieldType());
        }

        bool is_packed() const {
            return free_list_head == std::numeric_limits<_SkipfieldType>::max();
        }

        _AlignedEltPtr addr_of_element(size_type n) { return GroupAllocHelper::elements(this) + n; }
        overaligned_elt& element(size_type n) { return GroupAllocHelper::elements(this)[n]; }
        _AlignedEltPtr __end_of_elements() { return GroupAllocHelper::elements(this) + capacity; }

        _SkipfieldPtr addr_of_skipfield(size_type n) { return GroupAllocHelper::skipfield(this) + n; }
        _SkipfieldType& skipfield(size_type n) { return GroupAllocHelper::skipfield(this)[n]; }

        _SkipfieldType index_of_last_endpoint() { return last_endpoint - addr_of_element(0); }

        void reset(_SkipfieldType increment, _GroupPtr next, _GroupPtr prev, size_type groupno) {
            last_endpoint = addr_of_element(increment);
            next_group = next;
            free_list_head = std::numeric_limits<_SkipfieldType>::max();
            prev_group = prev;
            size = increment;
            next_erasure_ = nullptr;
            set_group_number(groupno);
            std::fill_n(addr_of_skipfield(0), capacity, _SkipfieldType());
        }
    };

    template <bool _IsConst>
    class __hive_iterator {
        _GroupPtr group_ = _GroupPtr();
        _SkipfieldType idx_ = 0;

    public:
#if PLF_HIVE_DEBUGGING
        void debug_dump() const {
            printf("iterator(");
            if (group_) printf("#%zu", group_->group_number());
            else printf("null");
            printf(", %zu)\n", size_t(idx_));
        }
#endif // PLF_HIVE_DEBUGGING

#if PLF_HIVE_RANDOM_ACCESS_ITERATORS
        using iterator_category = std::random_access_iterator_tag;
#else
        using iterator_category = std::bidirectional_iterator_tag;
#endif
        using value_type = typename hive::value_type;
        using difference_type = typename hive::difference_type;
        using pointer = std::conditional_t<_IsConst, typename hive::const_pointer, typename hive::pointer>;
        using reference = std::conditional_t<_IsConst, typename hive::const_reference, typename hive::reference>;

        friend class hive;
        friend class __hive_reverse_iterator<false>;
        friend class __hive_reverse_iterator<true>;

        explicit __hive_iterator() = default;
        __hive_iterator(__hive_iterator&&) = default;
        __hive_iterator(const __hive_iterator&) = default;
        __hive_iterator& operator=(__hive_iterator&&) = default;
        __hive_iterator& operator=(const __hive_iterator&) = default;

        template<bool _IsConst_ = _IsConst, class = std::enable_if_t<_IsConst_>>
        __hive_iterator(const __hive_iterator<false>& rhs) :
            group_(rhs.group_),
            idx_(rhs.idx_)
        {}

        template<bool _IsConst_ = _IsConst, class = std::enable_if_t<_IsConst_>>
        __hive_iterator(__hive_iterator<false>&& rhs) :
            group_(std::move(rhs.group_)),
            idx_(std::move(rhs.idx_))
        {}

        friend void swap(__hive_iterator& a, __hive_iterator& b) noexcept {
            using std::swap;
            swap(a.group_, b.group_);
            swap(a.idx_, b.idx_);
        }

        friend bool operator==(const __hive_iterator&, const __hive_iterator&) = default;

#if PLF_HIVE_RELATIONAL_OPERATORS
        friend std::strong_ordering operator<=>(const __hive_iterator& a, const __hive_iterator& b) {
            return a.group_ == b.group_ ?
                a.idx_ <=> b.idx_ :
                a.group_->groupno_ <=> b.group_->groupno_;
        }
#endif

        inline reference operator*() const noexcept {
            return *group_->element(idx_).t();
        }

        inline pointer operator->() const noexcept {
            return group_->element(idx_).t();
        }

        __hive_iterator& operator++() {
            _LIBCPP_ASSERT(group_ != nullptr, "");
            auto inc = 1 + group_->skipfield(idx_ + 1);
            idx_ += inc;
            if (idx_ == group_->index_of_last_endpoint() && group_->next_group != nullptr) {
                group_ = group_->next_group;
                idx_ = group_->skipfield(0);
            }
            return *this;
        }

        __hive_iterator& operator--() {
            _LIBCPP_ASSERT(group_ != nullptr, "");
            if (idx_ != 0) {
                _SkipfieldType dec = group_->skipfield(idx_ - 1);
                if (dec != idx_) {
                   idx_ -= dec + 1;
                   return *this;
                }
            }
            group_ = group_->prev_group;
            idx_ = group_->capacity - 1 - group_->skipfield(group_->capacity - 1);
            return *this;
        }

        inline __hive_iterator operator++(int) { auto copy = *this; ++*this; return copy; }
        inline __hive_iterator operator--(int) { auto copy = *this; --*this; return copy; }

    private:
        template<bool _IsConst_ = _IsConst, class = std::enable_if_t<_IsConst_>>
        __hive_iterator<false> unconst() const {
            __hive_iterator<false> it;
            it.group_ = group_;
            it.idx_ = idx_;
            return it;
        }

        explicit __hive_iterator(_GroupPtr g, size_t idx) :
            group_(g), idx_(idx) {}

        void advance_forward(difference_type n) {
            _LIBCPP_ASSERT(n > 0, "");
            _LIBCPP_ASSERT(group_ != nullptr, "");

            if (idx_ != group_->skipfield(0)) {
                _SkipfieldType endpoint = group_->index_of_last_endpoint();
                while (true) {
                    ++idx_;
                    idx_ += group_->skipfield(idx_);
                    --n;
                    if (idx_ == endpoint) {
                        break;
                    } else if (n == 0) {
                        return;
                    }
                }
                if (group_->next_group == nullptr) {
                    return;
                }
                group_ = group_->next_group;
                if (n == 0) {
                    idx_ = group_->skipfield(0);
                    return;
                }
            }

            while (static_cast<difference_type>(group_->size) <= n) {
                if (group_->next_group == nullptr) {
                    idx_ = group_->index_of_last_endpoint();
                    return;
                } else {
                    n -= group_->size;
                    group_ = group_->next_group;
                    if (n == 0) {
                        idx_ = group_->skipfield(0);
                        return;
                    }
                }
            }

            if (group_->is_packed()) {
                idx_ = n;
            } else {
                idx_ = group_->skipfield(0);
                do {
                    idx_ += 1 + group_->skipfield(idx_ + 1);
                } while (--n != 0);
            }
        }

        void advance_backward(difference_type n) {
            _LIBCPP_ASSERT(n < 0, "");
            _LIBCPP_ASSERT(!(idx_ == group_->skipfield(0) && group_->prev_group == nullptr), "");

            if (idx_ != group_->index_of_last_endpoint()) {
                if (group_->is_packed()) {
                    difference_type distance_from_beginning = -static_cast<difference_type>(idx_);
                    if (n >= distance_from_beginning) {
                        idx_ += n;
                        return;
                    } else if (group_->prev_group == nullptr) {
                        idx_ = 0;
                        return;
                    } else {
                        n -= distance_from_beginning;
                    }
                } else {
                    _SkipfieldType beginning_point = group_->skipfield(0);
                    while (idx_ != beginning_point) {
                        --idx_;
                        idx_ -= group_->skipfield(idx_);
                        if (++n == 0) {
                            return;
                        }
                    }
                    if (group_->prev_group == nullptr) {
                        idx_ = group_->skipfield(0);
                        return;
                    }
                }
                group_ = group_->prev_group;
            }

            while (n < -static_cast<difference_type>(group_->size)) {
                if (group_->prev_group == nullptr) {
                    idx_ = group_->skipfield(0);
                    return;
                }
                n += group_->size;
                group_ = group_->prev_group;
            }

            if (n == -static_cast<difference_type>(group_->size)) {
                idx_ = group_->skipfield(0);
            } else if (group_->is_packed()) {
                idx_ = group_->size + n;
            } else {
                idx_ = group_->index_of_last_endpoint();
                do {
                    --idx_;
                    idx_ -= group_->skipfield(idx_);
                } while (++n != 0);
            }
        }

        inline difference_type index_in_group() const { return idx_; }

        difference_type distance_from_start_of_group() const {
            _LIBCPP_ASSERT(group_ != nullptr, "");
            if (group_->is_packed() || idx_ == 0) {
                return idx_;
            } else {
                difference_type count = 0;
                _SkipfieldType endpoint = group_->index_of_last_endpoint();
                for (_SkipfieldType i = idx_; i != endpoint; ++count) {
                    ++i;
                    i += group_->skipfield(i);
                }
                return group_->size - count;
            }
        }

        difference_type distance_from___end_of_group() const {
            _LIBCPP_ASSERT(group_ != nullptr, "");
            if (group_->is_packed() || idx_ == 0) {
                return group_->size - idx_;
            } else {
                difference_type count = 0;
                _SkipfieldType endpoint = group_->index_of_last_endpoint();
                for (_SkipfieldType i = idx_; i != endpoint; ++count) {
                    ++i;
                    i += group_->skipfield(i);
                }
                return count;
            }
        }

        difference_type distance_forward(__hive_iterator last) const {
            if (last.group_ != group_) {
                difference_type count = last.distance_from_start_of_group();
                for (_GroupPtr g = last.group_->prev_group; g != group_; g = g->prev_group) {
                    count += g->size;
                }
                return count + this->distance_from___end_of_group();
            } else if (idx_ == last.idx_) {
                return 0;
            } else if (group_->is_packed()) {
                return last.idx_ - idx_;
            } else {
                difference_type count = 0;
                while (last.idx_ != idx_) {
                    --last.idx_;
                    last.idx_ -= last.group_->skipfield(last.idx_);
                    ++count;
                }
                return count;
            }
        }

    public:
        inline void advance(difference_type n) {
            if (n > 0) {
                advance_forward(n);
            } else if (n < 0) {
                advance_backward(n);
            }
        }

        inline __hive_iterator next(difference_type n) const {
            auto copy = *this;
            copy.advance(n);
            return copy;
        }

        inline __hive_iterator prev(difference_type n) const {
            auto copy = *this;
            copy.advance(-n);
            return copy;
        }

        difference_type distance(__hive_iterator last) const {
#if PLF_HIVE_RELATIONAL_OPERATORS
            if (last < *this) {
                return -last.distance_forward(*this);
            }
#endif
            return distance_forward(last);
        }

#if PLF_HIVE_RANDOM_ACCESS_ITERATORS
        friend __hive_iterator& operator+=(__hive_iterator& a, difference_type n) { a.advance(n); return a; }
        friend __hive_iterator& operator-=(__hive_iterator& a, difference_type n) { a.advance(-n); return a; }
        friend __hive_iterator operator+(const __hive_iterator& a, difference_type n) { return a.next(n); }
        friend __hive_iterator operator+(difference_type n, const __hive_iterator& a) { return a.next(n); }
        friend __hive_iterator operator-(const __hive_iterator& a, difference_type n) { return a.prev(n); }
        friend difference_type operator-(const __hive_iterator& a, const __hive_iterator& b) { return b.distance(a); }
        reference operator[](difference_type n) const { return *next(n); }
#endif
    }; // class __hive_iterator

    template <bool _IsConst>
    class __hive_reverse_iterator {
        __hive_iterator<_IsConst> it_;

    public:
#if PLF_HIVE_RANDOM_ACCESS_ITERATORS
        using iterator_category = std::random_access_iterator_tag;
#else
        using iterator_category = std::bidirectional_iterator_tag;
#endif
        using value_type = typename hive::value_type;
        using difference_type = typename hive::difference_type;
        using pointer = std::conditional_t<_IsConst, typename hive::const_pointer, typename hive::pointer>;
        using reference = std::conditional_t<_IsConst, typename hive::const_reference, typename hive::reference>;

        __hive_reverse_iterator() = default;
        __hive_reverse_iterator(__hive_reverse_iterator&&) = default;
        __hive_reverse_iterator(const __hive_reverse_iterator&) = default;
        __hive_reverse_iterator& operator=(__hive_reverse_iterator&&) = default;
        __hive_reverse_iterator& operator=(const __hive_reverse_iterator&) = default;

        template<bool _IsConst_ = _IsConst, class = std::enable_if_t<_IsConst_>>
        __hive_reverse_iterator(const __hive_reverse_iterator<false>& rhs) :
            it_(rhs.base())
        {}

        explicit __hive_reverse_iterator(__hive_iterator<_IsConst>&& rhs) : it_(std::move(rhs)) {}
        explicit __hive_reverse_iterator(const __hive_iterator<_IsConst>& rhs) : it_(rhs) {}

        friend bool operator==(const __hive_reverse_iterator& a, const __hive_reverse_iterator& b) = default;

#if PLF_HIVE_RELATIONAL_OPERATORS
        friend std::strong_ordering operator<=>(const __hive_reverse_iterator& a, const __hive_reverse_iterator& b) { return (b.it_ <=> a.it_); }
#endif

        inline reference operator*() const noexcept { auto jt = it_; --jt; return *jt; }
        inline pointer operator->() const noexcept { auto jt = it_; --jt; return jt.operator->(); }
        __hive_reverse_iterator& operator++() { --it_; return *this; }
        __hive_reverse_iterator operator++(int) { auto copy = *this; --it_; return copy; }
        __hive_reverse_iterator& operator--() { ++it_; return *this; }
        __hive_reverse_iterator operator--(int) { auto copy = *this; ++it_; return copy; }

        __hive_iterator<_IsConst> base() const noexcept { return it_; }

        __hive_reverse_iterator next(difference_type n) const {
            auto copy = *this;
            copy.it_.advance(-n);
            return copy;
        }

        __hive_reverse_iterator prev(difference_type n) const {
            auto copy = *this;
            copy.it_.advance(n);
            return copy;
        }

        difference_type distance(const __hive_reverse_iterator &last) const {
            return last.it_.distance(it_);
        }

        void advance(difference_type n) {
            it_.advance(-n);
        }

#if PLF_HIVE_RANDOM_ACCESS_ITERATORS
        friend __hive_reverse_iterator& operator+=(__hive_reverse_iterator& a, difference_type n) { a.advance(n); return a; }
        friend __hive_reverse_iterator& operator-=(__hive_reverse_iterator& a, difference_type n) { a.advance(-n); return a; }
        friend __hive_reverse_iterator operator+(const __hive_reverse_iterator& a, difference_type n) { return a.next(n); }
        friend __hive_reverse_iterator operator+(difference_type n, const __hive_reverse_iterator& a) { return a.next(n); }
        friend __hive_reverse_iterator operator-(const __hive_reverse_iterator& a, difference_type n) { return a.prev(n); }
        friend difference_type operator-(const __hive_reverse_iterator& a, const __hive_reverse_iterator& b) { return b.distance(a); }
        reference operator[](difference_type n) const { return *next(n); }
#endif
    }; // __hive_reverse_iterator

public:
    void assert_invariants() const {
#if PLF_HIVE_DEBUGGING
        assert(size_ <= capacity_);
#if !PLF_HIVE_P2596
        assert(min_group_capacity_ <= max_group_capacity_);
#endif
        if (size_ == 0) {
            assert(__begin_ == __end_);
            if (capacity_ == 0) {  // TODO FIXME BUG HACK: this should be `if (true)`
                assert(__begin_.group_ == nullptr);
                assert(__begin_.idx_ == 0);
                assert(__end_.group_ == nullptr);
                assert(__end_.idx_ == 0);
            }
            assert(__groups_with_erasures_ == nullptr);
            if (capacity_ == 0) {
                assert(__unused_groups_ == nullptr);
            } else {
                if (__begin_.group_ == nullptr) {
                    assert(__unused_groups_ != nullptr);  // the capacity must be somewhere
                }
            }
        } else {
            assert(__begin_.group_ != nullptr);
            assert(__begin_.group_->prev_group == nullptr);
            assert(__end_.group_ != nullptr);
            assert(__end_.idx_ == __end_.group_->index_of_last_endpoint());
            assert(__end_.group_->next_group == nullptr);
            assert(__begin_ != __end_);
            if (capacity_ == size_) {
                assert(__unused_groups_ == nullptr);
            }
        }
        size_type total_size = 0;
        size_type total_cap = 0;
        for (_GroupPtr g = __begin_.group_; g != nullptr; g = g->next_group) {
#if !PLF_HIVE_P2596
            assert(min_group_capacity_ <= g->capacity);
            assert(g->capacity <= max_group_capacity_);
#endif
            // assert(g->size >= 1); // TODO FIXME BUG HACK
            assert(g->size <= g->capacity);
            total_size += g->size;
            total_cap += g->capacity;
            if (g->is_packed()) {
                assert(g->last_endpoint == g->addr_of_element(g->size));
            } else {
                assert(g->size < g->capacity);
                assert(g->last_endpoint > g->addr_of_element(g->size));
                assert(g->skipfield(g->free_list_head) != 0);
            }
            if (g->last_endpoint != g->__end_of_elements()) {
                assert(g == __end_.group_);
                assert(g->next_group == nullptr);
            }
            assert(g->skipfield(g->last_endpoint - g->addr_of_element(0)) == 0);
            if (g->size != g->capacity && g->next_group != nullptr) {
                assert(!g->is_packed());
            }
#if PLF_HIVE_RELATIONAL_OPERATORS
            if (g->next_group != nullptr) {
                assert(g->group_number() < g->next_group->group_number());
            }
#endif
            _SkipfieldType total_skipped = 0;
            for (_SkipfieldType sb = g->free_list_head; sb != std::numeric_limits<_SkipfieldType>::max(); sb = g->element(sb).nextlink_) {
                _SkipfieldType skipblock_length = g->skipfield(sb);
                assert(skipblock_length != 0);
                assert(g->skipfield(sb + skipblock_length - 1) == skipblock_length);
                total_skipped += skipblock_length;
                if (sb == g->free_list_head) {
                    assert(g->element(sb).prevlink_ == std::numeric_limits<_SkipfieldType>::max());
                }
                if (g->element(sb).nextlink_ != std::numeric_limits<_SkipfieldType>::max()) {
                    assert(g->element(g->element(sb).nextlink_).prevlink_ == sb);
                }
            }
            if (g == __end_.group_) {
                assert(g->capacity == g->size + total_skipped + (g->__end_of_elements() - g->last_endpoint));
            } else {
                assert(g->capacity == g->size + total_skipped);
            }
        }
        assert(total_size == size_);
        assert((__unused_groups_ != nullptr) == (__unused_groups_tail_ != nullptr));
        for (_GroupPtr g = __unused_groups_; g != nullptr; g = g->next_group) {
#if !PLF_HIVE_P2596
            assert(min_group_capacity_ <= g->capacity);
            assert(g->capacity <= max_group_capacity_);
#endif
            total_cap += g->capacity;
            if (g->next_group == nullptr) {
                assert(__unused_groups_tail_ == g);
            }
        }
        assert(total_cap == capacity_);
        if (size_ == capacity_) {
            assert(__groups_with_erasures_ == nullptr);
            assert(__unused_groups_ == nullptr);
        } else {
            size_type space_in_last_group = __end_.group_ != nullptr ? (__end_.group_->capacity - __end_.idx_) : 0;
            assert(size_ + space_in_last_group == capacity_ || __groups_with_erasures_ != nullptr || __unused_groups_ != nullptr);
        }
        for (_GroupPtr g = __groups_with_erasures_; g != nullptr; g = g->next_erasure_) {
            assert(g->size < g->capacity);
        }
#endif
    }

    void debug_dump() const {
#if PLF_HIVE_DEBUGGING
        printf(
            "hive [%zu/%zu used] (erase=%p, unused=%p, mincap=%zu, maxcap=%zu)\n",
            size_t(size_), size_t(capacity_),
            __groups_with_erasures_, __unused_groups_,
#if PLF_HIVE_P2596
            size_t(impl_min_block_size()), size_t(impl_max_block_size())
#else
            size_t(min_group_capacity_), size_t(max_group_capacity_)
#endif
        );
        printf("  begin="); __begin_.debug_dump();
        size_t total = 0;
        group *prev = nullptr;
        for (auto *g = __begin_.group_; g != nullptr; g = g->next_group) {
            g->debug_dump();
            total += g->size;
            assert(g->prev_group == prev);
            prev = g;
        }
        assert(total == size_);
        printf("  end="); __end_.debug_dump();
        if (__end_.group_) {
            assert(__end_.group_->next_group == nullptr);
        }
        printf("UNUSED GROUPS:\n");
        for (auto *g = __unused_groups_; g != nullptr; g = g->next_group) {
            g->debug_dump();
            assert(g != __begin_.group_);
            assert(g != __end_.group_);
        }
        printf("GROUPS WITH ERASURES:");
        for (auto *g = __groups_with_erasures_; g != nullptr; g = g->next_erasure_) {
            printf(" %zu", g->group_number());
        }
        printf("\n");
#endif // PLF_HIVE_DEBUGGING
    }

private:
    iterator __end_;
    iterator __begin_;
    _GroupPtr __groups_with_erasures_ = _GroupPtr();
    _GroupPtr __unused_groups_ = _GroupPtr();
    _GroupPtr __unused_groups_tail_ = _GroupPtr();
    size_type size_ = 0;
    size_type capacity_ = 0;
    allocator_type allocator_;
#if !PLF_HIVE_P2596
    _SkipfieldType min_group_capacity_ = block_capacity_hard_limits().min;
    _SkipfieldType max_group_capacity_ = block_capacity_hard_limits().max;
#endif

#if !PLF_HIVE_P2596
    static inline void check_limits(hive_limits soft) {
        auto hard = block_capacity_hard_limits();
        if (!(hard.min <= soft.min && soft.min <= soft.max && soft.max <= hard.max)) {
            std::__throw_length_error("Supplied limits are outside the allowable range");
        }
    }
#endif

    size_type trailing_capacity() const {
        if (__end_.group_ == nullptr) {
            return 0;
        } else {
            return (__end_.group_->capacity - __end_.index_in_group());
        }
    }

    void blank() {
        __end_ = iterator();
        __begin_ = iterator();
        __groups_with_erasures_ = nullptr;
        __unused_groups_ = nullptr;
        __unused_groups_tail_ = nullptr;
        size_ = 0;
        capacity_ = 0;
    }

#if PLF_HIVE_RELATIONAL_OPERATORS
    void renumber_all_groups() {
        size_type groupno = 0;
        for (_GroupPtr g = __begin_.group_; g != nullptr; g = g->next_group) {
            g->set_group_number(groupno++);
        }
    }
#else
    inline void renumber_all_groups() { }
#endif

public:
    hive() = default;
    explicit hive(const allocator_type &alloc) : allocator_(alloc) {}
    hive(const hive& h) : hive(h, std::allocator_traits<allocator_type>::select_on_container_copy_construction(h.allocator_)) {}

#if PLF_HIVE_P2596
    hive(const hive& h, const type_identity_t<allocator_type>& alloc) :
        allocator_(alloc)
    {
        reserve(h.size());
        range_assign_impl(h.begin(), h.end());
    }
#else
    explicit hive(hive_limits limits) :
        min_group_capacity_(static_cast<_SkipfieldType>(limits.min)),
        max_group_capacity_(static_cast<_SkipfieldType>(limits.max))
    {
        check_limits(limits);
    }

    hive(hive_limits limits, const allocator_type &alloc) :
        allocator_(alloc),
        min_group_capacity_(static_cast<_SkipfieldType>(limits.min)),
        max_group_capacity_(static_cast<_SkipfieldType>(limits.max))
    {
        check_limits(limits);
    }

    hive(const hive& source, const type_identity_t<allocator_type>& alloc) :
        allocator_(alloc),
        min_group_capacity_(static_cast<_SkipfieldType>((source.min_group_capacity_ > source.size_) ? source.min_group_capacity_ : ((source.size_ > source.max_group_capacity_) ? source.max_group_capacity_ : source.size_))),
        max_group_capacity_(source.max_group_capacity_)
    {
        reserve(source.size());
        range_assign_impl(source.begin(), source.end());
        min_group_capacity_ = source.min_group_capacity_;
    }
#endif

    hive(hive&& source) noexcept :
        __end_(std::move(source.__end_)),
        __begin_(std::move(source.__begin_)),
        __groups_with_erasures_(std::move(source.__groups_with_erasures_)),
        __unused_groups_(std::move(source.__unused_groups_)),
        size_(source.size_),
        capacity_(source.capacity_),
        allocator_(source.get_allocator())
#if !PLF_HIVE_P2596
        , min_group_capacity_(source.min_group_capacity_)
        , max_group_capacity_(source.max_group_capacity_)
#endif
    {
        _LIBCPP_ASSERT(&source != this, "");
        source.blank();
    }

    hive(hive&& source, const type_identity_t<allocator_type>& alloc) : hive(alloc)
    {
        _LIBCPP_ASSERT(&source != this, "");
        bool should_use_source_allocator = (
            std::allocator_traits<allocator_type>::is_always_equal::value ||
            alloc == source.get_allocator()
        );
        if (should_use_source_allocator) {
            *this = std::move(source);
        } else {
#if !PLF_HIVE_P2596
            reshape(source.block_capacity_limits());
#endif
            reserve(source.size());
            range_assign_impl(std::make_move_iterator(source.begin()), std::make_move_iterator(source.end()));
        }
    }

    hive(size_type n, const T& value, const allocator_type &alloc = allocator_type()) :
        allocator_(alloc)
    {
        assign(n, value);
    }

    explicit hive(size_type n) { assign(n, T()); }

    hive(size_type n, const allocator_type &alloc) :
        allocator_(alloc)
    {
        assign(n, T());
    }

    template<class It, class = std::enable_if_t<!std::is_integral<It>::value>>
    hive(It first, It last)
    {
        assign(std::move(first), std::move(last));
    }

    template<class It, class = std::enable_if_t<!std::is_integral<It>::value>>
    hive(It first, It last, const allocator_type &alloc) :
        allocator_(alloc)
    {
        assign(std::move(first), std::move(last));
    }

    hive(std::initializer_list<T> il, const type_identity_t<allocator_type>& alloc = allocator_type()) :
        allocator_(alloc)
    {
        assign(il.begin(), il.end());
    }

#if !PLF_HIVE_P2596
    hive(size_type n, const T& value, hive_limits limits, const allocator_type &alloc = allocator_type()) :
        allocator_(alloc),
        min_group_capacity_(static_cast<_SkipfieldType>(limits.min)),
        max_group_capacity_(static_cast<_SkipfieldType>(limits.max))
    {
        check_limits(limits);
        assign(n, value);
    }

    hive(size_type n, hive_limits limits, const allocator_type &alloc = allocator_type()) :
        allocator_(alloc),
        min_group_capacity_(static_cast<_SkipfieldType>(limits.min)),
        max_group_capacity_(static_cast<_SkipfieldType>(limits.max))
    {
        check_limits(limits);
        assign(n, T());
    }

    template<class It, class = std::enable_if_t<!std::is_integral<It>::value>>
    hive(It first, It last, hive_limits limits, const allocator_type &alloc = allocator_type()) :
        allocator_(alloc),
        min_group_capacity_(static_cast<_SkipfieldType>(limits.min)),
        max_group_capacity_(static_cast<_SkipfieldType>(limits.max))
    {
        check_limits(limits);
        assign(std::move(first), std::move(last));
    }

    hive(std::initializer_list<T> il, hive_limits limits, const allocator_type &alloc = allocator_type()):
        allocator_(alloc),
        min_group_capacity_(static_cast<_SkipfieldType>(limits.min)),
        max_group_capacity_(static_cast<_SkipfieldType>(limits.max))
    {
        check_limits(limits);
        assign(il.begin(), il.end());
    }
#endif

#if 0 // TODO: P1206 from_range constructors
    template<std::ranges::input_range R>
        requires std::convertible_to<std::ranges::range_reference_t<R>, T>
    hive(std::from_range_t, R&& rg)
    {
        assign_range(std::forward<R>(rg));
    }

    template<std::ranges::input_range R>
        requires std::convertible_to<std::ranges::range_reference_t<R>, T>
    hive(std::from_range_t, R&& rg, const allocator_type &alloc) :
        allocator_(alloc)
    {
        assign_range(std::forward<R>(rg));
    }

#if !PLF_HIVE_P2596
    template<std::ranges::input_range R>
        requires std::convertible_to<std::ranges::range_reference_t<R>, T>
    explicit hive(std::from_range_t, R&& rg, hive_limits limits, const allocator_type &alloc = allocator_type()) :
        allocator_(alloc),
        min_group_capacity_(static_cast<_SkipfieldType>(limits.min)),
        max_group_capacity_(static_cast<_SkipfieldType>(limits.max))
    {
        check_limits(limits);
        assign_range(std::forward<R>(rg));
    }
#endif // !PLF_HIVE_P2596
#endif // TODO: P1206 from_range constructors

    ~hive() {
        assert_invariants();
        destroy_all_data();
    }

private:
    struct GroupAllocHelper {
        union U {
            group g_;
            overaligned_elt elt_;
        };
        struct type {
            alignas(U) char dummy;
        };

        static inline _AlignedEltPtr elements(_GroupPtr g) {
            auto p = PtrOf<char>(g);
            p += sizeof(U);
            return _AlignedEltPtr(p);
        }

        static inline _SkipfieldPtr skipfield(_GroupPtr g) {
            return _SkipfieldPtr(elements(g) + g->capacity);
        }

        static _GroupPtr allocate_group(allocator_type a, size_t cap) {
            auto ta = AllocOf<type>(a);
            size_t bytes_for_group = sizeof(U);
            size_t bytes_for_elts = sizeof(overaligned_elt) * cap;
            size_t bytes_for_skipfield = sizeof(_SkipfieldType) * (cap + 1);
            size_t n = (bytes_for_group + bytes_for_elts + bytes_for_skipfield + sizeof(type) - 1) / sizeof(type);
            PtrOf<type> p = std::allocator_traits<AllocOf<type>>::allocate(ta, n);
            _GroupPtr g = PtrOf<group>(p);
            ::new (bitcast_pointer<void*>(g)) group(cap);
            return g;
        }
        static void deallocate_group(allocator_type a, _GroupPtr g) {
            size_t cap = g->capacity;
            auto ta = AllocOf<type>(a);
            size_t bytes_for_group = sizeof(U);
            size_t bytes_for_elts = sizeof(overaligned_elt) * cap;
            size_t bytes_for_skipfield = sizeof(_SkipfieldType) * (cap + 1);
            size_t n = (bytes_for_group + bytes_for_elts + bytes_for_skipfield + sizeof(type) - 1) / sizeof(type);
            std::allocator_traits<AllocOf<type>>::deallocate(ta, PtrOf<type>(g), n);
        }
    };

    void allocate_unused_group(size_type cap) {
        _GroupPtr g = GroupAllocHelper::allocate_group(get_allocator(), cap);
        __unused_groups_push_front(g);
        capacity_ += cap;
    }

    inline void deallocate_group(_GroupPtr g) {
        GroupAllocHelper::deallocate_group(get_allocator(), g);
    }

    void unspecialcase___end_group(_GroupPtr g) {
        _LIBCPP_ASSERT(g == __end_.group_, "");
        size_type trailing = g->__end_of_elements() - g->last_endpoint;
        size_type sb = g->capacity - trailing;
        if (trailing != 0) {
            g->skipfield(sb) = trailing;
            g->skipfield(g->capacity - 1) = trailing;
            if (g->free_list_head == std::numeric_limits<_SkipfieldType>::max()) {
                g->next_erasure_ = std::exchange(__groups_with_erasures_, g);
            }
            g->element(sb).nextlink_ = std::exchange(g->free_list_head, sb);
            g->element(sb).prevlink_ = std::numeric_limits<_SkipfieldType>::max();
            g->last_endpoint = g->__end_of_elements();
        }
    }

    void destroy_all_data() {
        if (_GroupPtr g = __begin_.group_) {
            __end_.group_->next_group = __unused_groups_;

            if constexpr (!std::is_trivially_destructible<T>::value) {
                if (size_ != 0) {
                    while (true) {
                        // Erase elements without bothering to update skipfield - much faster:
                        _SkipfieldType __end_pointer = g->index_of_last_endpoint();
                        do {
                            std::allocator_traits<allocator_type>::destroy(allocator_, __begin_.operator->());
                            __begin_.idx_ += 1 + __begin_.group_->skipfield(__begin_.idx_ + 1);
                        } while (__begin_.idx_ != __end_pointer); // ie. beyond end of available data

                        _GroupPtr next = g->next_group;
                        deallocate_group(g);
                        g = next;

                        if (g == __unused_groups_) {
                            break;
                        }
                        __begin_ = iterator(g, g->skipfield(0));
                    }
                }
            }

            while (g != nullptr) {
                _GroupPtr next = g->next_group;
                deallocate_group(g);
                g = next;
            }
        }
    }

public:
    template<class... Args>
    iterator emplace(Args&&... args) {
        allocator_type ea = get_allocator();
        if (trailing_capacity() != 0) {
            iterator result = __end_;
            _GroupPtr g = result.group_;
            std::allocator_traits<allocator_type>::construct(ea, result.operator->(), static_cast<Args&&>(args)...);
            _LIBCPP_ASSERT(__end_.group_->skipfield(__end_.idx_) == 0, "");
            ++__end_.idx_;
            g->last_endpoint += 1;
            g->size += 1;
            ++size_;
            assert_invariants();
            return result;
        } else if (__groups_with_erasures_ != nullptr) {
            _GroupPtr g = __groups_with_erasures_;
            _SkipfieldType sb = g->free_list_head;
            _LIBCPP_ASSERT(sb < g->capacity, "");
            auto result = iterator(g, sb);
            _SkipfieldType nextsb = g->element(sb).nextlink_;
            _LIBCPP_ASSERT(g->element(sb).prevlink_ == std::numeric_limits<_SkipfieldType>::max(), "");
            hive_try_rollback([&]() {
                std::allocator_traits<allocator_type>::construct(ea, result.operator->(), static_cast<Args&&>(args)...);
            }, [&]() {
                g->element(sb).prevlink_ = std::numeric_limits<_SkipfieldType>::max();
                g->element(sb).nextlink_ = nextsb;
            });
            g->size += 1;
            size_ += 1;
            if (g == __begin_.group_ && sb == 0) {
                __begin_ = result;
            }
            _SkipfieldType old_skipblock_length = std::exchange(g->skipfield(sb), 0);
            _LIBCPP_ASSERT(1 <= old_skipblock_length && old_skipblock_length <= g->capacity, "");
            _SkipfieldType new_skipblock_length = (old_skipblock_length - 1);
            if (new_skipblock_length == 0) {
                g->free_list_head = nextsb;
                if (nextsb == std::numeric_limits<_SkipfieldType>::max()) {
                    __groups_with_erasures_ = g->next_erasure_;
                } else {
                    g->element(nextsb).prevlink_ = std::numeric_limits<_SkipfieldType>::max();
                }
            } else {
                g->skipfield(sb + 1) = new_skipblock_length;
                g->skipfield(sb + old_skipblock_length - 1) = new_skipblock_length;
                g->free_list_head = sb + 1;
                g->element(sb + 1).prevlink_ = std::numeric_limits<_SkipfieldType>::max();
                g->element(sb + 1).nextlink_ = nextsb;
                if (nextsb != std::numeric_limits<_SkipfieldType>::max()) {
                    g->element(nextsb).prevlink_ = sb + 1;
                }
            }
            assert_invariants();
            return result;
        } else {
            if (__unused_groups_ == nullptr) {
                allocate_unused_group(recommend_block_size());
            }
            _GroupPtr g = __unused_groups_;
            std::allocator_traits<allocator_type>::construct(ea, g->element(0).t(), static_cast<Args&&>(args)...);
            (void)__unused_groups_pop_front();
            std::fill_n(g->addr_of_skipfield(0), g->capacity, _SkipfieldType());
            g->size = 1;
            g->last_endpoint = g->addr_of_element(1);
            g->free_list_head = std::numeric_limits<_SkipfieldType>::max();
            g->next_group = nullptr;
            g->prev_group = __end_.group_;
            auto result = iterator(g, 0);
            if (__end_.group_ != nullptr) {
                if (__end_.group_->group_number() == std::numeric_limits<size_type>::max()) {
                    renumber_all_groups();
                }
                __end_.group_->next_group = g;
                g->set_group_number(__end_.group_->group_number() + 1);
            } else {
                __begin_ = result;
                g->set_group_number(0);
            }
            __end_ = iterator(g, 1);
            ++size_;
            return result;
        }
    }

    inline iterator insert(const T& value) { return emplace(value); }
    inline iterator insert(T&& value) { return emplace(std::move(value)); }

    void insert(size_type n, const T& value) {
        if (n == 0) {
            // do nothing
        } else if (n == 1) {
            insert(value);
        } else {
            callback_insert_impl(n, make_value_callback(n, value));
        }
    }

    template<class It, std::enable_if_t<!std::is_integral<It>::value>* = nullptr>
    inline void insert(It first, It last) {
        range_insert_impl(std::move(first), std::move(last));
    }

#if 0 // TODO: P1206 insert_range
    template<std::ranges::input_range R>
        requires std::convertible_to<std::ranges::range_reference_t<R>, T>
    inline void insert_range(R&& rg) {
        if constexpr (std::ranges::sized_range<R&>) {
            reserve(size() + std::ranges::size(rg));
        }
        range_insert_impl(std::ranges::begin(rg), std::ranges::end(rg));
    }
#endif

    inline void insert(std::initializer_list<T> il) {
        range_insert_impl(il.begin(), il.end());
    }

    iterator erase(const_iterator it) {
        _LIBCPP_ASSERT(size_ != 0, "");
        _LIBCPP_ASSERT(it.group_ != nullptr, "");
        _LIBCPP_ASSERT(it.idx_ != it.group_->index_of_last_endpoint(), "");
        _LIBCPP_ASSERT(it.group_->skipfield(it.idx_) == 0, "");

        if constexpr (!std::is_trivially_destructible<T>::value) {
            allocator_type ea = get_allocator();
            std::allocator_traits<allocator_type>::destroy(ea, it.operator->());
        }

        _GroupPtr g = it.group_;

        --size_;
        --(g->size);

        if (g->size != 0) {
            const char prev_skipfield = (g->skipfield(it.idx_ - (it.idx_ != 0)) != 0);
            const char after_skipfield = (g->skipfield(it.idx_ + 1) != 0);
            _SkipfieldType update_value = 1;

            if (!(prev_skipfield | after_skipfield)) {
                g->skipfield(it.idx_) = 1;
                if (g->is_packed()) {
                    g->next_erasure_ = std::exchange(__groups_with_erasures_, g);
                } else {
                    g->element(g->free_list_head).prevlink_ = it.idx_;
                }
                g->element(it.idx_).nextlink_ = g->free_list_head;
                g->element(it.idx_).prevlink_ = std::numeric_limits<_SkipfieldType>::max();
                g->free_list_head = it.idx_;
            } else if (prev_skipfield & (!after_skipfield)) {
                // previous erased consecutive elements, none following
                _SkipfieldType new_skipblock_length = g->skipfield(it.idx_ - 1) + 1;
                g->skipfield(it.idx_) = new_skipblock_length;
                g->skipfield(it.idx_ - (new_skipblock_length - 1)) = new_skipblock_length;
            } else if ((!prev_skipfield) & after_skipfield) {
                // following erased consecutive elements, none preceding
                _SkipfieldType new_skipblock_length = g->skipfield(it.idx_ + 1) + 1;
                g->skipfield(it.idx_) = new_skipblock_length;
                g->skipfield(it.idx_ + (new_skipblock_length - 1)) = new_skipblock_length;

                const _SkipfieldType following_previous = g->element(it.idx_ + 1).nextlink_;
                const _SkipfieldType following_next = g->element(it.idx_ + 1).prevlink_;
                g->element(it.idx_).nextlink_ = following_previous;
                g->element(it.idx_).prevlink_ = following_next;

                const _SkipfieldType index = static_cast<_SkipfieldType>(it.index_in_group());

                if (following_previous != std::numeric_limits<_SkipfieldType>::max()) {
                    g->element(following_previous).prevlink_ = index;
                }

                if (following_next != std::numeric_limits<_SkipfieldType>::max()) {
                    g->element(following_next).nextlink_ = index;
                } else {
                    g->free_list_head = index;
                }
                update_value = new_skipblock_length;
            } else {
                // both preceding and following consecutive erased elements - erased element is between two skipblocks
                _SkipfieldType preceding_value = g->skipfield(it.idx_ - 1);
                _SkipfieldType following_value = g->skipfield(it.idx_ + 1);
                _SkipfieldType new_skipblock_length = preceding_value + following_value + 1;

                // Join the skipblocks
                g->skipfield(it.idx_ - preceding_value) = new_skipblock_length;
                g->skipfield(it.idx_ + following_value) = new_skipblock_length;

                // Remove the following skipblock's entry from the free list
                const _SkipfieldType following_previous = g->element(it.idx_ + 1).nextlink_;
                const _SkipfieldType following_next = g->element(it.idx_ + 1).prevlink_;

                if (following_previous != std::numeric_limits<_SkipfieldType>::max()) {
                    it.group_->element(following_previous).prevlink_ = following_next;
                }

                if (following_next != std::numeric_limits<_SkipfieldType>::max()) {
                    it.group_->element(following_next).nextlink_ = following_previous;
                } else {
                    it.group_->free_list_head = following_previous;
                }
                update_value = following_value + 1;
            }

            iterator result = it.unconst();
            result.idx_ += update_value;

            if (result.idx_ == g->index_of_last_endpoint() && g->next_group != nullptr) {
                result = iterator(g->next_group, g->next_group->skipfield(0));
            }

            if (it == __begin_) {
                __begin_ = result;
            }
            // assert_invariants();
            return result;
        } else {
            iterator result;
            if (g->next_group != nullptr && g->prev_group != nullptr) {
                g->next_group->prev_group = g->prev_group;
                g->prev_group->next_group = g->next_group;
                result = iterator(g->next_group, g->next_group->skipfield(0));
            } else if (g->next_group != nullptr) {
                g->next_group->prev_group = nullptr;
                __begin_ = iterator(g->next_group, g->next_group->skipfield(0));
                result = __begin_;
            } else if (g->prev_group != nullptr) {
                g->prev_group->next_group = nullptr;
                __end_ = iterator(g->prev_group, g->prev_group->capacity);
                result = __end_;
            } else {
                __begin_ = iterator();
                __end_ = iterator();
                result = __end_;
            }
            if (!g->is_packed()) {
                remove_from___groups_with_erasures_list(g);
            }
            __unused_groups_push_front(g);
            assert_invariants();
            return result;
        }
    }

    iterator erase(const_iterator first, const_iterator last) {
        allocator_type ea = get_allocator();
        const_iterator current = first;
        if (current.group_ != last.group_) {
            if (current.idx_ != current.group_->skipfield(0)) {
                size_type number_of_group_erasures = 0;
                _SkipfieldType end = first.group_->index_of_last_endpoint();
                if (std::is_trivially_destructible<T>::value && current.group_->is_packed()) {
                    number_of_group_erasures += static_cast<size_type>(current.group_->size - current.idx_);
                } else {
                    while (current.idx_ != end) {
                        if (current.group_->skipfield(current.idx_) == 0) {
                            if constexpr (!std::is_trivially_destructible<T>::value) {
                                std::allocator_traits<allocator_type>::destroy(ea, current.operator->());
                            }
                            ++number_of_group_erasures;
                            ++current.idx_;
                        } else {
                            const _SkipfieldType prev_free_list_index = current.group_->element(current.idx_).nextlink_;
                            const _SkipfieldType next_free_list_index = current.group_->element(current.idx_).prevlink_;
                            current.idx_ += current.group_->skipfield(current.idx_);
                            if (next_free_list_index == std::numeric_limits<_SkipfieldType>::max() && prev_free_list_index == std::numeric_limits<_SkipfieldType>::max()) {
                                remove_from___groups_with_erasures_list(first.group_);
                                first.group_->free_list_head = std::numeric_limits<_SkipfieldType>::max();
                                number_of_group_erasures += (end - current.idx_);
                                if constexpr (!std::is_trivially_destructible<T>::value) {
                                    while (current.idx_ != end) {
                                        std::allocator_traits<allocator_type>::destroy(ea, current.operator->());
                                        ++current.idx_;
                                    }
                                }
                                break; // end overall while loop
                            } else if (next_free_list_index == std::numeric_limits<_SkipfieldType>::max()) {
                                current.group_->free_list_head = prev_free_list_index; // make free list head equal to next free list node
                                current.group_->element(prev_free_list_index).prevlink_ = std::numeric_limits<_SkipfieldType>::max();
                            } else {
                                current.group_->element(next_free_list_index).nextlink_ = prev_free_list_index;
                                if (prev_free_list_index != std::numeric_limits<_SkipfieldType>::max()) {
                                    current.group_->element(prev_free_list_index).prevlink_ = next_free_list_index;
                                }
                            }
                        }
                    }
                }

                const _SkipfieldType previous_node_value = first.group_->skipfield(first.idx_ - 1);
                const _SkipfieldType distance_to_end = end - first.idx_;

                if (previous_node_value == 0) {
                    first.group_->skipfield(first.idx_) = distance_to_end;
                    first.group_->skipfield(first.idx_ + (distance_to_end - 1)) = distance_to_end;
                    if (first.group_->is_packed()) {
                        first.group_->next_erasure_ = std::exchange(__groups_with_erasures_, first.group_);
                    } else {
                        first.group_->element(first.group_->free_list_head).prevlink_ = first.idx_;
                    }

                    first.group_->element(first.idx_).nextlink_ = first.group_->free_list_head;
                    first.group_->element(first.idx_).prevlink_ = std::numeric_limits<_SkipfieldType>::max();
                    first.group_->free_list_head = first.idx_;
                } else {
                    _SkipfieldType new_skipblock_length = previous_node_value + distance_to_end;
                    first.group_->skipfield(first.idx_ - previous_node_value) = new_skipblock_length;
                    first.group_->skipfield(first.idx_ + (distance_to_end - 1)) = new_skipblock_length;
                }
                first.group_->size -= number_of_group_erasures;
                size_ -= number_of_group_erasures;
                current.group_ = current.group_->next_group;
            }

            // Intermediate groups:
            const _GroupPtr prev = current.group_->prev_group;
            while (current.group_ != last.group_) {
                if constexpr (!std::is_trivially_destructible<T>::value) {
                    current.idx_ = current.group_->skipfield(0);
                    _SkipfieldType end = current.group_->index_of_last_endpoint();
                    do {
                        std::allocator_traits<allocator_type>::destroy(ea, current.operator->());
                        current.idx_ += 1 + current.group_->skipfield(current.idx_ + 1);
                    } while (current.idx_ != end);
                }
                if (!current.group_->is_packed()) {
                    remove_from___groups_with_erasures_list(current.group_);
                }
                size_ -= current.group_->size;
                _GroupPtr current_group = std::exchange(current.group_, current.group_->next_group);
                __unused_groups_push_front(current_group);
            }

            current.idx_ = current.group_->skipfield(0);
            current.group_->prev_group = prev;

            if (prev != nullptr) {
                prev->next_group = current.group_;
            } else {
                __begin_ = last.unconst();
            }
        }

        _LIBCPP_ASSERT(current.group_ == last.group_, "");
        if (current == last) {
            assert_invariants();
            return last.unconst();
        }

        if (last != __end_ || current.idx_ != current.group_->skipfield(0)) {
            size_type number_of_group_erasures = 0;
            const_iterator current_saved = current;

            if (std::is_trivially_destructible<T>::value && current.group_->is_packed()) {
                number_of_group_erasures += (last.idx_ - current.idx_);
            } else {
                while (current.idx_ != last.idx_) {
                    if (current.group_->skipfield(current.idx_) == 0) {
                        if constexpr (!std::is_trivially_destructible<T>::value) {
                            std::allocator_traits<allocator_type>::destroy(ea, current.operator->());
                        }
                        ++number_of_group_erasures;
                        ++current.idx_;
                    } else {
                        const _SkipfieldType prev_free_list_index = current.group_->element(current.idx_).nextlink_;
                        const _SkipfieldType next_free_list_index = current.group_->element(current.idx_).prevlink_;

                        current.idx_ += current.group_->skipfield(current.idx_);

                        if (next_free_list_index == std::numeric_limits<_SkipfieldType>::max() && prev_free_list_index == std::numeric_limits<_SkipfieldType>::max()) {
                            remove_from___groups_with_erasures_list(last.group_);
                            last.group_->free_list_head = std::numeric_limits<_SkipfieldType>::max();
                            number_of_group_erasures += (last.idx_ - current.idx_);
                            if constexpr (!std::is_trivially_destructible<T>::value) {
                                while (current.idx_ != last.idx_) {
                                    std::allocator_traits<allocator_type>::destroy(ea, current.operator->());
                                    ++current.idx_;
                                }
                            }
                            break; // end overall while loop
                        } else if (next_free_list_index == std::numeric_limits<_SkipfieldType>::max()) {
                            current.group_->free_list_head = prev_free_list_index;
                            current.group_->element(prev_free_list_index).prevlink_ = std::numeric_limits<_SkipfieldType>::max();
                        } else {
                            current.group_->element(next_free_list_index).nextlink_ = prev_free_list_index;
                            if (prev_free_list_index != std::numeric_limits<_SkipfieldType>::max()) {
                                current.group_->element(prev_free_list_index).prevlink_ = next_free_list_index;
                            }
                        }
                    }
                }
            }

            const _SkipfieldType distance_to_last = (last.idx_ - current_saved.idx_);
            const _SkipfieldType index = current_saved.idx_;

            if (current_saved.idx_ == 0 || current_saved.group_->skipfield(current_saved.idx_ - 1) == 0) {
                current_saved.group_->skipfield(current_saved.idx_) = distance_to_last;
                last.group_->skipfield(last.idx_ - 1) = distance_to_last;

                if (last.group_->is_packed()) {
                    last.group_->next_erasure_ = std::exchange(__groups_with_erasures_, last.group_);
                } else {
                    last.group_->element(last.group_->free_list_head).prevlink_ = index;
                }

                current_saved.group_->element(current_saved.idx_).nextlink_ = last.group_->free_list_head;
                current_saved.group_->element(current_saved.idx_).prevlink_ = std::numeric_limits<_SkipfieldType>::max();
                last.group_->free_list_head = index;
            } else {
                _SkipfieldType prev_node_value = current_saved.group_->skipfield(current_saved.idx_ - 1);
                _SkipfieldType new_skipblock_length = prev_node_value + distance_to_last;
                current_saved.group_->skipfield(current_saved.idx_ - prev_node_value) = new_skipblock_length;
                last.group_->skipfield(last.idx_ - 1) = new_skipblock_length;
            }

            if (first == __begin_) {
                __begin_ = last.unconst();
            }
            last.group_->size -= number_of_group_erasures;
            size_ -= number_of_group_erasures;
        } else {
            if constexpr (!std::is_trivially_destructible<T>::value) {
                while (current.idx_ != last.idx_) {
                    std::allocator_traits<allocator_type>::destroy(ea, current.operator->());
                    current.idx_ += 1 + current.group_->skipfield(current.idx_ + 1);
                }
            }

            size_ -= current.group_->size;
            if (size_ != 0) {
                if (!current.group_->is_packed()) {
                    remove_from___groups_with_erasures_list(current.group_);
                }

                current.group_->prev_group->next_group = current.group_->next_group;

                if (current.group_ == __end_.group_) {
                    _GroupPtr prev = current.group_->prev_group;
                    __end_ = iterator(prev, prev->index_of_last_endpoint());
                    __unused_groups_push_front(current.group_);
                    return __end_;
                } else if (current.group_ == __begin_.group_) {
                    _GroupPtr next = current.group_->next_group;
                    __begin_ = iterator(next, next->skipfield(0));
                }

                if (current.group_->next_group != __end_.group_) {
                    capacity_ -= current.group_->capacity;
                } else {
                    __unused_groups_push_front(current.group_);
                    return last.unconst();
                }
            } else {
                reset_only_group_left(current.group_);
                return __end_;
            }

            deallocate_group(current.group_);  // TODO FIXME BUG HACK: don't do this
        }

        return last.unconst();
    }

    void swap(hive &source)
        noexcept(std::allocator_traits<allocator_type>::propagate_on_container_swap::value || std::allocator_traits<allocator_type>::is_always_equal::value)
    {
        using std::swap;
        swap(__end_, source.__end_);
        swap(__begin_, source.__begin_);
        swap(__groups_with_erasures_, source.__groups_with_erasures_);
        swap(__unused_groups_, source.__unused_groups_);
        swap(__unused_groups_tail_, source.__unused_groups_tail_);
        swap(size_, source.size_);
        swap(capacity_, source.capacity_);
#if !PLF_HIVE_P2596
        swap(min_group_capacity_, source.min_group_capacity_);
        swap(max_group_capacity_, source.max_group_capacity_);
#endif
        if constexpr (std::allocator_traits<allocator_type>::propagate_on_container_swap::value && !std::allocator_traits<allocator_type>::is_always_equal::value) {
            swap(allocator_, source.allocator_);
        }
    }

    friend void swap(hive& a, hive& b) noexcept(noexcept(a.swap(b))) { a.swap(b); }

    void clear() noexcept {
        if (size_ != 0) {
            if constexpr (!std::is_trivially_destructible<T>::value) {
                allocator_type ea = get_allocator();
                for (iterator it = __begin_; it != __end_; ++it) {
                    std::allocator_traits<allocator_type>::destroy(ea, it.operator->());
                }
            }
            if (__begin_.group_ != __end_.group_) {
                // Move all other groups onto the unused_groups list
                __end_.group_->next_group = __unused_groups_;
                if (__unused_groups_ == nullptr) {
                    __unused_groups_tail_ = __end_.group_;
                }
                __unused_groups_ = __begin_.group_->next_group;
            }
            reset_only_group_left(__begin_.group_);
            __groups_with_erasures_ = nullptr;
            size_ = 0;
        }
    }

    void splice(hive& source) {
        assert_invariants();
        source.assert_invariants();
        _LIBCPP_ASSERT(&source != this, "");

        if (capacity_ + source.capacity_ > max_size()) {
            std::__throw_length_error("Result of splice would exceed max_size()");
        }

#if !PLF_HIVE_P2596
        if (source.min_group_capacity_ < min_group_capacity_ || source.max_group_capacity_ > max_group_capacity_) {
            for (_GroupPtr it = source.__begin_.group_; it != nullptr; it = it->next_group) {
                if (it->capacity < min_group_capacity_ || it->capacity > max_group_capacity_) {
                    std::__throw_length_error("Cannot splice: source hive contains blocks that do not match the block limits of the destination hive");
                }
            }
        }
#endif

        size_type trailing = trailing_capacity();
        if (trailing > source.trailing_capacity()) {
            source.splice(*this);
            swap(source);
        } else {
            if (source.__groups_with_erasures_ != nullptr) {
                if (__groups_with_erasures_ == nullptr) {
                    __groups_with_erasures_ = source.__groups_with_erasures_;
                } else {
                    _GroupPtr tail = __groups_with_erasures_;
                    while (tail->next_erasure_ != nullptr) {
                        tail = tail->next_erasure_;
                    }
                    tail->next_erasure_ = source.__groups_with_erasures_;
                }
            }
            if (source.__unused_groups_ != nullptr) {
                if (__unused_groups_ == nullptr) {
                    __unused_groups_ = std::exchange(source.__unused_groups_, nullptr);
                } else {
                    __unused_groups_tail_->next_group = std::exchange(source.__unused_groups_, nullptr);
                }
                __unused_groups_tail_ = std::exchange(source.__unused_groups_tail_, nullptr);
            }
            if (trailing != 0 && source.__begin_.group_ != nullptr) {
                unspecialcase___end_group(__end_.group_);
            }
            if (source.__begin_.group_ != nullptr) {
                source.__begin_.group_->prev_group = __end_.group_;
                if (__end_.group_ != nullptr) {
                    __end_.group_->next_group = source.__begin_.group_;
#if PLF_HIVE_RELATIONAL_OPERATORS
                    if (source.__begin_.group_->group_number() <= __end_.group_->group_number()) {
                        renumber_all_groups();
                    }
#endif
                } else {
                    _LIBCPP_ASSERT(__begin_.group_ == nullptr, "");
                    __begin_ = std::move(source.__begin_);
                }
                __end_ = std::move(source.__end_);
            }
            size_ += std::exchange(source.size_, 0);
            capacity_ += std::exchange(source.capacity_, 0);

            source.__begin_ = iterator();
            source.__end_ = iterator();
            source.__groups_with_erasures_ = nullptr;
        }

        assert_invariants();
        source.assert_invariants();
    }

    inline void splice(hive&& source) { this->splice(source); }

private:
    template<bool MightFillIt, class CB>
    void callback_fill_skipblock(_SkipfieldType n, CB cb, _GroupPtr g) {
        _LIBCPP_ASSERT(g == __groups_with_erasures_, "");
        allocator_type ea = get_allocator();
        _SkipfieldType sb = g->free_list_head;
        _AlignedEltPtr d_first = g->addr_of_element(sb);
        _AlignedEltPtr d_last = d_first + n;
        _SkipfieldType nextsb = d_first[0].nextlink_;
        _SkipfieldType old_skipblock_length = g->skipfield(sb);
        _LIBCPP_ASSERT(1 <= n && n <= old_skipblock_length, "");
        _LIBCPP_ASSERT(g->skipfield(sb + old_skipblock_length - 1) == old_skipblock_length, "");
        _AlignedEltPtr p = d_first;
        hive_try_finally([&]() {
            while (p != d_last) {
                cb.construct_and_increment(ea, p);
            }
        }, [&]() {
            _SkipfieldType nadded = p - d_first;
            g->size += nadded;
            size_ += nadded;
            if (nadded != 0 && d_first == __begin_.group_->addr_of_element(0)) {
                __begin_ = iterator(g, 0);
            }
            std::fill_n(g->addr_of_skipfield(sb), nadded, _SkipfieldType());
            _SkipfieldType new_skipblock_length = (old_skipblock_length - nadded);
            if (MightFillIt && new_skipblock_length == 0) {
                g->free_list_head = nextsb;
                if (nextsb == std::numeric_limits<_SkipfieldType>::max()) {
                    __groups_with_erasures_ = g->next_erasure_;
                }
            } else {
                g->skipfield(sb + nadded) = new_skipblock_length;
                g->skipfield(sb + old_skipblock_length - 1) = new_skipblock_length;
                g->free_list_head = sb + nadded;
                g->element(sb + nadded).prevlink_ = std::numeric_limits<_SkipfieldType>::max();
                g->element(sb + nadded).nextlink_ = nextsb;
                if (nextsb != std::numeric_limits<_SkipfieldType>::max()) {
                    g->element(nextsb).prevlink_ = sb + nadded;
                }
            }
        });
    }

    template<class CB>
    void callback_fill_trailing_capacity(_SkipfieldType n, CB cb, _GroupPtr g) {
        allocator_type ea = get_allocator();
        _LIBCPP_ASSERT(g == __end_.group_, "");
        _LIBCPP_ASSERT(g->is_packed(), "");
        _LIBCPP_ASSERT(1 <= n && n <= g->capacity - g->size, "");
        _LIBCPP_ASSERT(g->next_group == nullptr, "");
        _AlignedEltPtr d_first = g->last_endpoint;
        _AlignedEltPtr d_last = g->last_endpoint + n;
        _AlignedEltPtr p = d_first;
        hive_try_finally([&]() {
            while (p != d_last) {
                cb.construct_and_increment(ea, p);
            }
        }, [&]() {
            _SkipfieldType nadded = p - d_first;
            g->last_endpoint = p;
            g->size += nadded;
            size_ += nadded;
            __end_ = iterator(g, p - g->addr_of_element(0));
        });
    }

    template<class CB>
    void callback_fill_unused_group(_SkipfieldType n, CB cb, _GroupPtr g) {
        if (__end_.group_ != nullptr && __end_.group_->group_number() == std::numeric_limits<size_type>::max()) {
            renumber_all_groups();
        }
        allocator_type ea = get_allocator();
        _LIBCPP_ASSERT(g == __unused_groups_, "");
        _LIBCPP_ASSERT(1 <= n && n <= g->capacity, "");
        _AlignedEltPtr d_first = g->addr_of_element(0);
        _AlignedEltPtr d_last = g->addr_of_element(n);
        _AlignedEltPtr p = d_first;
        hive_try_finally([&]() {
            while (p != d_last) {
                cb.construct_and_increment(ea, p);
            }
        }, [&]() {
            _SkipfieldType nadded = p - d_first;
            if (nadded != 0) {
                (void)__unused_groups_pop_front();
                std::fill_n(g->addr_of_skipfield(0), g->capacity, _SkipfieldType());
                g->free_list_head = std::numeric_limits<_SkipfieldType>::max();
                g->last_endpoint = p;
                g->size = nadded;
                size_ += nadded;
                g->next_group = nullptr;
                if (__end_.group_ != nullptr) {
                    if (__end_.group_->group_number() == std::numeric_limits<size_type>::max()) {
                        renumber_all_groups();
                    }
                    __end_.group_->next_group = g;
                    g->prev_group = __end_.group_;
                    g->set_group_number(__end_.group_->group_number() + 1);
                } else {
                    g->prev_group = nullptr;
                    g->set_group_number(0);
                }
                __end_ = iterator(g, nadded);
                if (__begin_.group_ == nullptr) {
                    __begin_ = iterator(g, 0);
                }
            } else {
                _LIBCPP_ASSERT(g == __unused_groups_, "");
                _LIBCPP_ASSERT(g != __end_.group_, "");
            }
        });
    }

    template<class CB>
    void callback_insert_impl(size_type n, CB cb) {
        reserve(size_ + n);
        assert_invariants();
        while (__groups_with_erasures_ != nullptr) {
            _GroupPtr g = __groups_with_erasures_;
            _LIBCPP_ASSERT(g->free_list_head != std::numeric_limits<_SkipfieldType>::max(), "");
            _SkipfieldType skipblock_length = g->skipfield(g->free_list_head);
            if (skipblock_length >= n) {
                callback_fill_skipblock<false>(n, cb, g);
                assert_invariants();
                return;
            } else {
                callback_fill_skipblock<true>(skipblock_length, cb, g);
                n -= skipblock_length;
            }
        }
        assert_invariants();
        if (n != 0 && __end_.group_ != nullptr) {
            _GroupPtr g = __end_.group_;
            _LIBCPP_ASSERT(g->is_packed(), "");
            size_type space = g->capacity - g->size;
            if (space >= n) {
                callback_fill_trailing_capacity(n, cb, g);
                assert_invariants();
                return;
            } else if (space != 0) {
                callback_fill_trailing_capacity(space, cb, g);
                n -= space;
            }
        }
        assert_invariants();
        while (n != 0) {
            _GroupPtr g = __unused_groups_;
            if (g->capacity >= n) {
                callback_fill_unused_group(n, cb, g);
                assert_invariants();
                return;
            } else {
                callback_fill_unused_group(g->capacity, cb, g);
                n -= g->capacity;
            }
        }
        assert_invariants();
    }

    template<class It, class Sent>
    inline void range_assign_impl(It first, Sent last) {
        if constexpr (!forward_iterator<It>) {
            clear();
            for ( ; first != last; ++first) {
                emplace(*first);
            }
        } else if (first == last) {
            clear();
        } else {
            size_type n = std::ranges::distance(first, last);
            clear();
            callback_insert_impl(n, make_itpair_callback(first, last));
            assert_invariants();
        }
    }

    template<class It, class Sent>
    void range_insert_impl(It first, Sent last) {
        if constexpr (!forward_iterator<It>) {
            for ( ; first != last; ++first) {
                emplace(*first);
            }
        } else if (first == last) {
            return;
        } else {
            size_type n = std::ranges::distance(first, last);
            callback_insert_impl(n, make_itpair_callback(first, last));
        }
    }

    inline void update_subsequent_group_numbers(_GroupPtr g) {
#if PLF_HIVE_RELATIONAL_OPERATORS
        do {
            g->groupno_ -= 1;
            g = g->next_group;
        } while (g != nullptr);
#endif
        (void)g;
    }

    void remove_from___groups_with_erasures_list(_GroupPtr g) {
        _LIBCPP_ASSERT(__groups_with_erasures_ != nullptr, "");
        if (g == __groups_with_erasures_) {
            __groups_with_erasures_ = __groups_with_erasures_->next_erasure_;
        } else {
            _GroupPtr prev = __groups_with_erasures_;
            _GroupPtr curr = __groups_with_erasures_->next_erasure_;
            while (g != curr) {
                prev = curr;
                curr = curr->next_erasure_;
            }
            prev->next_erasure_ = curr->next_erasure_;
        }
    }

    inline void reset_only_group_left(_GroupPtr g) {
        __groups_with_erasures_ = nullptr;
        g->reset(0, nullptr, nullptr, 0);
        __begin_ = iterator(g, 0);
        __end_ = __begin_;
    }

    inline void __unused_groups_push_front(_GroupPtr g) {
        g->next_group = std::exchange(__unused_groups_, g);
        if (__unused_groups_tail_ == nullptr) {
            __unused_groups_tail_ = g;
        }
    }

    inline _GroupPtr __unused_groups_pop_front() {
        _GroupPtr g = std::exchange(__unused_groups_, __unused_groups_->next_group);
        _LIBCPP_ASSERT(g != nullptr, "");
        if (__unused_groups_tail_ == g) {
            __unused_groups_tail_ = nullptr;
        }
        return g;
    }

public:
    template <class It, class = std::enable_if_t<!std::is_integral<It>::value>>
    inline void assign(It first, It last) {
        range_assign_impl(std::move(first), std::move(last));
    }

#if 0 // TODO: P1206 assign_range
    template<std::ranges::input_range R>
        requires std::convertible_to<std::ranges::range_reference_t<R>, T> &&
                 std::assignable_from<T&, std::ranges::range_reference_t<R>>
    inline void assign_range(R&& rg) {
        range_assign_impl(std::ranges::begin(rg), std::ranges::end(rg));
    }
#endif

    inline void assign(size_type n, const T& value) {
        clear();
        insert(n, value);
    }

    inline void assign(std::initializer_list<T> il) {
        range_assign_impl(il.begin(), il.end());
    }

    inline allocator_type get_allocator() const noexcept { return allocator_; }

    inline iterator begin() noexcept { return __begin_; }
    inline const_iterator begin() const noexcept { return __begin_; }
    inline iterator end() noexcept { return __end_; }
    inline const_iterator end() const noexcept { return __end_; }
    inline reverse_iterator rbegin() noexcept { return reverse_iterator(__end_); }
    inline const_reverse_iterator rbegin() const noexcept { return const_reverse_iterator(__end_); }
    inline reverse_iterator rend() noexcept { return reverse_iterator(__begin_); }
    inline const_reverse_iterator rend() const noexcept { return const_reverse_iterator(__begin_); }

    inline const_iterator cbegin() const noexcept { return __begin_; }
    inline const_iterator cend() const noexcept { return __end_; }
    inline const_reverse_iterator crbegin() const noexcept { return const_reverse_iterator(__end_); }
    inline const_reverse_iterator crend() const noexcept { return const_reverse_iterator(__begin_); }

    [[nodiscard]] inline bool empty() const noexcept { return size_ == 0; }
    inline size_type size() const noexcept { return size_; }
    inline size_type max_size() const noexcept { return std::allocator_traits<allocator_type>::max_size(get_allocator()); }
    inline size_type capacity() const noexcept { return capacity_; }

#if PLF_HIVE_P2596
    inline size_type max_block_size() const noexcept {
        size_type a = impl_max_block_size();
        size_type b = max_size();
        return a < b ? a : b;
    }
#endif

private:
    static constexpr size_type impl_min_block_size() { return 3; }
    static constexpr size_type impl_max_block_size() { return std::numeric_limits<_SkipfieldType>::max(); }

    inline size_type recommend_block_size() const {
        size_type r = size_;
        if (r < 8) r = 8;
#if PLF_HIVE_P2596
        if (r > impl_max_block_size()) r = impl_max_block_size();
#else
        if (r < min_group_capacity_) r = min_group_capacity_;
        if (r > max_group_capacity_) r = max_group_capacity_;
#endif
        return r;
    }

    void reserve_impl(size_type n, size_type min, size_type max) {
        if (n <= capacity_) {
            return;
        } else if (n > max_size()) {
            std::__throw_length_error("n must be at most max_size()");
        }
        size_type needed = n - capacity_;
        while (needed >= max) {
            allocate_unused_group(max);
            needed -= max;
        }
        if (needed != 0) {
            if (needed < min) {
                needed = min;
            }
            bool should_move_to_back_of_list = (__unused_groups_ != nullptr && __unused_groups_->capacity > needed);
            allocate_unused_group(needed);
            if (should_move_to_back_of_list) {
                _GroupPtr g = __unused_groups_pop_front();
                std::exchange(__unused_groups_tail_, g)->next_group = g;
                g->next_group = nullptr;
            }
        }
        _LIBCPP_ASSERT(capacity_ >= n, "");
        assert_invariants();
    }

    void reshape_impl_deallocate_unused_groups(size_t min, size_t max) {
        _GroupPtr g = __unused_groups_;
        _GroupPtr prev = nullptr;
        while (g != nullptr) {
            if (g->capacity < min || g->capacity > max) {
                if (prev != nullptr) {
                    prev->next_group = g->next_group;
                } else {
                    __unused_groups_ = g->next_group;
                }
                if (g->next_group == nullptr) {
                    __unused_groups_tail_ = prev;
                }
                capacity_ -= g->capacity;
                deallocate_group(std::exchange(g, g->next_group));
            } else {
                prev = std::exchange(g, g->next_group);
            }
        }
    }

    void transfer_group_impl(hive& h, _GroupPtr g) {
        if (g->prev_group != nullptr && g->next_group != nullptr) {
            g->prev_group->next_group = g->next_group;
            g->next_group->prev_group = g->prev_group;
        } else if (g->prev_group != nullptr) {
            g->prev_group->next_group = g->next_group;
            h.__end_ = iterator(g->prev_group, g->prev_group->capacity);
        } else if (g->next_group != nullptr) {
            g->next_group->prev_group = g->prev_group;
            h.__begin_ = iterator(g->next_group, g->next_group->skipfield(0));
        } else {
            h.__begin_ = iterator();
            h.__end_ = iterator();
        }
        if (!g->is_packed()) {
            h.remove_from___groups_with_erasures_list(g);
            g->next_erasure_ = std::exchange(__groups_with_erasures_, g);
        }
        h.capacity_ -= g->capacity;
        h.size_ -= g->size;
        g->next_group = nullptr;
        g->prev_group = __end_.group_;
        if (__end_.group_ != nullptr) {
            __end_.group_->next_group = g;
        } else {
            __begin_ = iterator(g, g->skipfield(0));
        }
        __end_ = iterator(g, g->index_of_last_endpoint());
        capacity_ += g->capacity;
        size_ += g->size;
    }

public:
#if PLF_HIVE_P2596
    bool reshape(size_type min, size_type n = 0) {
        if (n > max_size()) {
            std::__throw_length_error("n must be at most max_size()");
        }
        if (min > max_block_size()) {
            std::__throw_length_error("min must be at most max_block_size()");
        }
        reshape_impl_deallocate_unused_groups(min, std::numeric_limits<size_type>::max());
        size_type oldsize = size();
        hive other(get_allocator());
        for (_GroupPtr g = __begin_.group_; g != nullptr; ) {
            _GroupPtr next = g->next_group;
            _LIBCPP_ASSERT(g->size >= 1, "");
            if (g->capacity < min) {
                other.transfer_group_impl(*this, g);
            }
            g = next;
        }
        assert_invariants();
        other.assert_invariants();
        if (other.empty()) {
            return false;
        } else {
            hive_try_rollback([&]() {
                reserve_impl(oldsize, min, max_block_size());
                while (!other.empty()) {
                    emplace(std::move(*other.begin()));
                    other.erase(other.begin());
                }
            }, [&]() {
                this->splice(other);
            });
            return true;
        }
    }
#else
    void reshape(hive_limits limits) {
        check_limits(limits);
        assert_invariants();

        reshape_impl_deallocate_unused_groups(limits.min, limits.max);

        for (_GroupPtr g = __begin_.group_; g != nullptr; g = g->next_group) {
            if (g->capacity < limits.min || g->capacity > limits.max) {
                hive temp(limits, get_allocator());
                temp.range_assign_impl(std::make_move_iterator(begin()), std::make_move_iterator(end()));
                this->swap(temp);
                return;
            }
        }
        min_group_capacity_ = limits.min;
        max_group_capacity_ = limits.max;
    }

    inline hive_limits block_capacity_limits() const noexcept {
        return hive_limits(min_group_capacity_, max_group_capacity_);
    }

    static constexpr hive_limits block_capacity_hard_limits() noexcept {
        return hive_limits(impl_min_block_size(), std::numeric_limits<_SkipfieldType>::max());
    }
#endif

    hive& operator=(const hive& source) {
        if constexpr (std::allocator_traits<allocator_type>::propagate_on_container_copy_assignment::value) {
            allocator_type source_allocator(source);
            if (!std::allocator_traits<allocator_type>::is_always_equal::value && get_allocator() != source.get_allocator()) {
                // Deallocate existing blocks as source allocator is not necessarily able to do so
                destroy_all_data();
                blank();
            }
            allocator_ = source.get_allocator();
        }
        range_assign_impl(source.begin(), source.end());
        return *this;
    }

    hive& operator=(hive&& source)
        noexcept(std::allocator_traits<allocator_type>::propagate_on_container_move_assignment::value ||
                 std::allocator_traits<allocator_type>::is_always_equal::value)
    {
        _LIBCPP_ASSERT(&source != this, "");
        destroy_all_data();

        bool should_use_source_allocator = (
            std::allocator_traits<allocator_type>::propagate_on_container_move_assignment::value ||
            std::allocator_traits<allocator_type>::is_always_equal::value ||
            this->get_allocator() == source.get_allocator()
        );
        if (should_use_source_allocator) {
            constexpr bool can_just_memcpy = (
                std::is_trivially_copyable<allocator_type>::value &&
                std::is_trivial<_GroupPtr>::value &&
                std::is_trivial<_AlignedEltPtr>::value &&
                std::is_trivial<_SkipfieldPtr>::value
            );
            if constexpr (can_just_memcpy) {
                ::__builtin_memcpy(static_cast<void *>(this), &source, sizeof(hive));
            } else {
                __end_ = std::move(source.__end_);
                __begin_ = std::move(source.__begin_);
                __groups_with_erasures_ = std::move(source.__groups_with_erasures_);
                __unused_groups_ = std::move(source.__unused_groups_);
                __unused_groups_tail_ = std::move(source.__unused_groups_tail_);
                size_ = source.size_;
                capacity_ = source.capacity_;
#if !PLF_HIVE_P2596
                min_group_capacity_ = source.min_group_capacity_;
                max_group_capacity_ = source.max_group_capacity_;
#endif
                if constexpr (std::allocator_traits<allocator_type>::propagate_on_container_move_assignment::value) {
                    allocator_ = std::move(source.allocator_);
                }
            }
        } else {
            reserve(source.size());
            range_assign_impl(std::make_move_iterator(source.begin()), std::make_move_iterator(source.end()));
            source.destroy_all_data();
        }

        source.blank();
        assert_invariants();
        return *this;
    }

    inline hive& operator=(std::initializer_list<T> il) {
        range_assign_impl(il.begin(), il.end());
        assert_invariants();
        return *this;
    }

    void shrink_to_fit() {
#if PLF_HIVE_P2596
        const size_type min = impl_min_block_size();
        const size_type max = impl_max_block_size();
#else
        const size_type min = min_group_capacity_;
        const size_type max = max_group_capacity_;
#endif
        trim_capacity();
        size_type oldsize = size();
        hive other(get_allocator());
        for (_GroupPtr g = __begin_.group_; g != nullptr; ) {
            _GroupPtr next = g->next_group;
            if (next != nullptr) {
                if (g->size != max) {
                    other.transfer_group_impl(*this, g);
                }
            } else {
                if (g->capacity > min && g->capacity > g->size) {
                    other.transfer_group_impl(*this, g);
                }
            }
            g = next;
        }
        assert_invariants();
        other.assert_invariants();
        if (!other.empty()) {
            hive_try_rollback([&]() {
                reserve(oldsize);
                while (!other.empty()) {
                    emplace(std::move(*other.begin()));
                    other.erase(other.begin());
                }
            }, [&]() {
                this->splice(other);
            });
        }
    }

    void trim_capacity() noexcept {
        for (_GroupPtr g = __unused_groups_; g != nullptr; ) {
            _GroupPtr next = g->next_group;
            capacity_ -= g->capacity;
            deallocate_group(g);
            g = next;
        }
        __unused_groups_ = nullptr;
        __unused_groups_tail_ = nullptr;
        assert_invariants();
    }

    void reserve(size_type n) {
#if PLF_HIVE_P2596
        reserve_impl(n, impl_min_block_size(), impl_max_block_size());
#else
        reserve_impl(n, min_group_capacity_, max_group_capacity_);
#endif
    }

private:
    struct item_index_tuple {
        pointer original_location;
        size_type original_index;

        explicit item_index_tuple(pointer _item, size_type _index) :
            original_location(_item),
            original_index(_index)
        {}
    };

public:
    template <class Comp>
    void sort(Comp less) {
        if (size_ <= 1) {
            return;
        }

        struct ItemT {
            T *ptr_;
            size_type idx_;
        };

        std::unique_ptr<ItemT[]> a = std::make_unique<ItemT[]>(size_);
        auto it = __begin_;
        for (size_type i = 0; i < size_; ++i) {
            a[i] = ItemT{std::addressof(*it), i};
            ++it;
        }
        _LIBCPP_ASSERT(it == __end_, "");
        std::sort(a.get(), a.get() + size_, [&](const ItemT& a, const ItemT& b) { return less(*a.ptr_, *b.ptr_); });

        for (size_type i = 0; i < size_; ++i) {
            size_type src = a[i].idx_;
            size_type dest = i;
            if (src != dest) {
                T temp = std::move(*a[i].ptr_);
                do {
                    *a[dest].ptr_ = std::move(*a[src].ptr_);
                    dest = src;
                    src = a[dest].idx_;
                    a[dest].idx_ = dest;
                } while (src != i);
                *a[dest].ptr_ = std::move(temp);
            }
        }
        assert_invariants();
    }

    inline void sort() { sort(std::less<T>()); }

    template<class Comp>
    size_type unique(Comp eq) {
        size_type count = 0;
        auto end = cend();
        for (auto it = cbegin(); it != end; ) {
            auto previous = it++;
            if (it == end) {
                break;
            }
            if (eq(*it, *previous)) {
                auto orig = ++count;
                auto last = it;
                while (++last != end && eq(*last, *previous)) {
                    ++count;
                }
                if (count != orig) {
                    it = erase(it, last);
                } else {
                    it = erase(it);
                }
                end = cend();
            }
        }
        assert_invariants();
        return count;
    }

    inline size_type unique() { return unique(std::equal_to<T>()); }
};

    template<class T, class A, class Pred>
    typename hive<T, A>::size_type erase_if(hive<T, A>& h, Pred pred) {
        typename hive<T, A>::size_type count = 0;
        auto end = h.end();
        for (auto it = h.begin(); it != end; ++it) {
            if (pred(*it)) {
                auto orig = ++count;
                auto last = it;
                while (++last != end && pred(*last)) {
                    ++count;
                }
                if (count != orig) {
                    it = h.erase(it, last);
                } else {
                    it = h.erase(it);
                }
                end = h.end();
                if (it == end) {
                    break;
                }
            }
        }
        return count;
    }

    template<class T, class A>
    inline typename hive<T, A>::size_type erase(hive<T, A>& h, const T& value) {
        return std::erase_if(h, [&](const T &x) { return x == value; });
    }

_LIBCPP_END_NAMESPACE_STD

_LIBCPP_POP_MACROS

#endif // _LIBCPP_STD_VER >= 23

#endif // _LIBCPP_HIVE
